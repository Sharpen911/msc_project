{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for the model on embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, log_loss, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('features/both_.pkl', 'rb') as f:\n",
    "    both_feature = pickle.load(f)\n",
    "both_feature.dropna(inplace = True)\n",
    "both_feature.reset_index(inplace = True)\n",
    "both_feature.drop(both_feature.columns[0], axis=1,inplace = True)\n",
    "both_feature.drop(labels = both_feature[both_feature.ethnicity.eq('other')].index,inplace =True)\n",
    "\n",
    "both_feature[\"ethnicity\"].replace({\"asian\":\"asian/hispanic\",\"hispanic\":\"asian/hispanic\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013014</td>\n",
       "      <td>0.009834</td>\n",
       "      <td>0.032839</td>\n",
       "      <td>0.068315</td>\n",
       "      <td>-0.044134</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.030566</td>\n",
       "      <td>-0.059018</td>\n",
       "      <td>0.036496</td>\n",
       "      <td>0.053272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066769</td>\n",
       "      <td>-0.017998</td>\n",
       "      <td>-0.029152</td>\n",
       "      <td>-0.030382</td>\n",
       "      <td>-0.008150</td>\n",
       "      <td>-0.041132</td>\n",
       "      <td>-0.010102</td>\n",
       "      <td>-0.002104</td>\n",
       "      <td>female</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008530</td>\n",
       "      <td>0.028461</td>\n",
       "      <td>0.005318</td>\n",
       "      <td>0.067734</td>\n",
       "      <td>0.055008</td>\n",
       "      <td>-0.019989</td>\n",
       "      <td>0.035583</td>\n",
       "      <td>0.017593</td>\n",
       "      <td>0.042480</td>\n",
       "      <td>0.036743</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.105774</td>\n",
       "      <td>-0.055145</td>\n",
       "      <td>-0.059845</td>\n",
       "      <td>-0.024338</td>\n",
       "      <td>0.026859</td>\n",
       "      <td>-0.021318</td>\n",
       "      <td>-0.035750</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>female</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008398</td>\n",
       "      <td>0.013814</td>\n",
       "      <td>0.026279</td>\n",
       "      <td>0.059204</td>\n",
       "      <td>-0.035989</td>\n",
       "      <td>-0.000249</td>\n",
       "      <td>0.020220</td>\n",
       "      <td>-0.052055</td>\n",
       "      <td>0.024714</td>\n",
       "      <td>0.036616</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055981</td>\n",
       "      <td>-0.005376</td>\n",
       "      <td>-0.019954</td>\n",
       "      <td>-0.021236</td>\n",
       "      <td>-0.003274</td>\n",
       "      <td>-0.037816</td>\n",
       "      <td>-0.010013</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>female</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.005295</td>\n",
       "      <td>0.035029</td>\n",
       "      <td>0.029599</td>\n",
       "      <td>0.045612</td>\n",
       "      <td>-0.039439</td>\n",
       "      <td>-0.005130</td>\n",
       "      <td>0.001551</td>\n",
       "      <td>-0.074083</td>\n",
       "      <td>0.006280</td>\n",
       "      <td>0.015165</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040974</td>\n",
       "      <td>0.026522</td>\n",
       "      <td>-0.008702</td>\n",
       "      <td>-0.027052</td>\n",
       "      <td>0.006684</td>\n",
       "      <td>-0.037407</td>\n",
       "      <td>-0.026165</td>\n",
       "      <td>0.019598</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003955</td>\n",
       "      <td>0.025402</td>\n",
       "      <td>0.031767</td>\n",
       "      <td>0.076054</td>\n",
       "      <td>-0.050051</td>\n",
       "      <td>0.003772</td>\n",
       "      <td>0.016501</td>\n",
       "      <td>-0.075485</td>\n",
       "      <td>0.021640</td>\n",
       "      <td>0.035710</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061038</td>\n",
       "      <td>0.008354</td>\n",
       "      <td>-0.023504</td>\n",
       "      <td>-0.034003</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>-0.040405</td>\n",
       "      <td>-0.017716</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>female</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18723</th>\n",
       "      <td>-0.026155</td>\n",
       "      <td>0.025003</td>\n",
       "      <td>0.053989</td>\n",
       "      <td>0.060878</td>\n",
       "      <td>-0.019046</td>\n",
       "      <td>0.011664</td>\n",
       "      <td>-0.004236</td>\n",
       "      <td>-0.051848</td>\n",
       "      <td>-0.015985</td>\n",
       "      <td>0.040313</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033202</td>\n",
       "      <td>0.036435</td>\n",
       "      <td>-0.016155</td>\n",
       "      <td>-0.021178</td>\n",
       "      <td>-0.019340</td>\n",
       "      <td>-0.034092</td>\n",
       "      <td>-0.039857</td>\n",
       "      <td>0.073136</td>\n",
       "      <td>female</td>\n",
       "      <td>asian/hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18724</th>\n",
       "      <td>0.014630</td>\n",
       "      <td>0.018524</td>\n",
       "      <td>0.029416</td>\n",
       "      <td>0.095410</td>\n",
       "      <td>-0.050798</td>\n",
       "      <td>0.008691</td>\n",
       "      <td>0.021943</td>\n",
       "      <td>-0.074146</td>\n",
       "      <td>0.041119</td>\n",
       "      <td>0.063127</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082996</td>\n",
       "      <td>0.005862</td>\n",
       "      <td>-0.040526</td>\n",
       "      <td>-0.034719</td>\n",
       "      <td>-0.010274</td>\n",
       "      <td>-0.040530</td>\n",
       "      <td>0.001933</td>\n",
       "      <td>-0.005288</td>\n",
       "      <td>female</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18725</th>\n",
       "      <td>-0.012798</td>\n",
       "      <td>0.026301</td>\n",
       "      <td>0.013004</td>\n",
       "      <td>0.019854</td>\n",
       "      <td>-0.027733</td>\n",
       "      <td>-0.003602</td>\n",
       "      <td>-0.003783</td>\n",
       "      <td>-0.050443</td>\n",
       "      <td>-0.002319</td>\n",
       "      <td>-0.000319</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012225</td>\n",
       "      <td>0.024374</td>\n",
       "      <td>-0.000841</td>\n",
       "      <td>-0.022976</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>-0.018816</td>\n",
       "      <td>-0.024448</td>\n",
       "      <td>0.020594</td>\n",
       "      <td>male</td>\n",
       "      <td>asian/hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18726</th>\n",
       "      <td>-0.031794</td>\n",
       "      <td>0.042449</td>\n",
       "      <td>0.076959</td>\n",
       "      <td>0.065255</td>\n",
       "      <td>-0.023424</td>\n",
       "      <td>0.039190</td>\n",
       "      <td>-0.009896</td>\n",
       "      <td>-0.074889</td>\n",
       "      <td>-0.002837</td>\n",
       "      <td>0.062427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022544</td>\n",
       "      <td>0.052662</td>\n",
       "      <td>0.006829</td>\n",
       "      <td>-0.021299</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>-0.058646</td>\n",
       "      <td>-0.046015</td>\n",
       "      <td>0.090401</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18727</th>\n",
       "      <td>-0.019369</td>\n",
       "      <td>0.025804</td>\n",
       "      <td>0.017759</td>\n",
       "      <td>0.039805</td>\n",
       "      <td>-0.006279</td>\n",
       "      <td>0.024021</td>\n",
       "      <td>0.019578</td>\n",
       "      <td>-0.051419</td>\n",
       "      <td>-0.001171</td>\n",
       "      <td>0.033957</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022153</td>\n",
       "      <td>0.048068</td>\n",
       "      <td>-0.037023</td>\n",
       "      <td>-0.045473</td>\n",
       "      <td>-0.046018</td>\n",
       "      <td>-0.017155</td>\n",
       "      <td>-0.036364</td>\n",
       "      <td>0.068615</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18689 rows × 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.013014  0.009834  0.032839  0.068315 -0.044134  0.005859  0.030566   \n",
       "1      0.008530  0.028461  0.005318  0.067734  0.055008 -0.019989  0.035583   \n",
       "2      0.008398  0.013814  0.026279  0.059204 -0.035989 -0.000249  0.020220   \n",
       "3     -0.005295  0.035029  0.029599  0.045612 -0.039439 -0.005130  0.001551   \n",
       "4      0.003955  0.025402  0.031767  0.076054 -0.050051  0.003772  0.016501   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "18723 -0.026155  0.025003  0.053989  0.060878 -0.019046  0.011664 -0.004236   \n",
       "18724  0.014630  0.018524  0.029416  0.095410 -0.050798  0.008691  0.021943   \n",
       "18725 -0.012798  0.026301  0.013004  0.019854 -0.027733 -0.003602 -0.003783   \n",
       "18726 -0.031794  0.042449  0.076959  0.065255 -0.023424  0.039190 -0.009896   \n",
       "18727 -0.019369  0.025804  0.017759  0.039805 -0.006279  0.024021  0.019578   \n",
       "\n",
       "              7         8         9  ...       292       293       294  \\\n",
       "0     -0.059018  0.036496  0.053272  ... -0.066769 -0.017998 -0.029152   \n",
       "1      0.017593  0.042480  0.036743  ... -0.105774 -0.055145 -0.059845   \n",
       "2     -0.052055  0.024714  0.036616  ... -0.055981 -0.005376 -0.019954   \n",
       "3     -0.074083  0.006280  0.015165  ... -0.040974  0.026522 -0.008702   \n",
       "4     -0.075485  0.021640  0.035710  ... -0.061038  0.008354 -0.023504   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "18723 -0.051848 -0.015985  0.040313  ... -0.033202  0.036435 -0.016155   \n",
       "18724 -0.074146  0.041119  0.063127  ... -0.082996  0.005862 -0.040526   \n",
       "18725 -0.050443 -0.002319 -0.000319  ... -0.012225  0.024374 -0.000841   \n",
       "18726 -0.074889 -0.002837  0.062427  ... -0.022544  0.052662  0.006829   \n",
       "18727 -0.051419 -0.001171  0.033957  ... -0.022153  0.048068 -0.037023   \n",
       "\n",
       "            295       296       297       298       299  gender  \\\n",
       "0     -0.030382 -0.008150 -0.041132 -0.010102 -0.002104  female   \n",
       "1     -0.024338  0.026859 -0.021318 -0.035750  0.001282  female   \n",
       "2     -0.021236 -0.003274 -0.037816 -0.010013  0.001785  female   \n",
       "3     -0.027052  0.006684 -0.037407 -0.026165  0.019598    male   \n",
       "4     -0.034003  0.001051 -0.040405 -0.017716  0.009700  female   \n",
       "...         ...       ...       ...       ...       ...     ...   \n",
       "18723 -0.021178 -0.019340 -0.034092 -0.039857  0.073136  female   \n",
       "18724 -0.034719 -0.010274 -0.040530  0.001933 -0.005288  female   \n",
       "18725 -0.022976  0.001680 -0.018816 -0.024448  0.020594    male   \n",
       "18726 -0.021299  0.001269 -0.058646 -0.046015  0.090401  female   \n",
       "18727 -0.045473 -0.046018 -0.017155 -0.036364  0.068615    male   \n",
       "\n",
       "            ethnicity  \n",
       "0               black  \n",
       "1               black  \n",
       "2               black  \n",
       "3               white  \n",
       "4               black  \n",
       "...               ...  \n",
       "18723  asian/hispanic  \n",
       "18724           black  \n",
       "18725  asian/hispanic  \n",
       "18726           white  \n",
       "18727           white  \n",
       "\n",
       "[18689 rows x 302 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "both_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gender, X_test_gender, y_train_gender, y_test_gender = train_test_split(both_feature.drop(columns = ['gender','ethnicity']), both_feature['gender'], test_size=0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gender = pd.concat([X_train_gender,X_test_gender],ignore_index = True)\n",
    "y_gender = pd.concat([y_train_gender,y_test_gender],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=70, n_estimators=500)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'max_depth':[70,80,90,100],'n_estimators':[100,500],'criterion':['gini', 'entropy']}\n",
    "\n",
    "rf = GridSearchCV(RandomForestClassifier(),parameters)\n",
    "rf.fit(X_gender, y_gender)\n",
    "\n",
    "rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(dual=False, max_iter=10000, penalty='l1', tol=0.01)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'penalty': ['l1','l2']}\n",
    "                   \n",
    "svm_Linear = GridSearchCV(LinearSVC(dual = False,tol=1e-3,max_iter = 10000),parameters)\n",
    "svm_Linear.fit(X_gender, y_gender)\n",
    "svm_Linear.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'max_depth':[3,5,6] }\n",
    "                   \n",
    "GBC = GridSearchCV(GradientBoostingClassifier(n_estimators = 100),parameters)\n",
    "GBC.fit(X_gender, y_gender)\n",
    "GBC.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_eth, X_test_eth, y_train_eth, y_test_eth = train_test_split(both_feature.drop(columns = ['gender','ethnicity']), both_feature['ethnicity'], test_size=0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eth = pd.concat([X_train_eth,X_test_eth],ignore_index = True)\n",
    "y_eth = pd.concat([y_train_eth,y_test_eth],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
       "                       max_depth=90, n_estimators=500)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'max_depth':[70,80,90,100],'n_estimators':[100,500],'criterion':['gini', 'entropy']}\n",
    "\n",
    "rf = GridSearchCV(RandomForestClassifier(class_weight = 'balanced'),parameters)\n",
    "rf.fit(X_eth, y_eth)\n",
    "rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(class_weight='balanced', dual=False, max_iter=15000, penalty='l1',\n",
       "          tol=0.01)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'penalty': ['l1','l2']}\n",
    "                   \n",
    "svmLinear = GridSearchCV(LinearSVC(dual = False,class_weight = 'balanced',tol=1e-2,max_iter = 15000),parameters)\n",
    "svmLinear.fit(X_eth, y_eth)\n",
    "svmLinear.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'max_depth':[3,5,7] }\n",
    "                   \n",
    "GBC = GridSearchCV(GradientBoostingClassifier(),parameters)\n",
    "GBC.fit(X_eth, y_eth)\n",
    "GBC.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for BOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_df_path = 'usage_per_user/'\n",
    "\n",
    "with open(parent_df_path+'joh_df.pkl', 'rb') as f:\n",
    "    joh_per_usage = pickle.load(f)\n",
    "    \n",
    "with open(parent_df_path+'lon_df.pkl', 'rb') as f:\n",
    "    lon_per_usage = pickle.load(f)\n",
    "    \n",
    "with open(parent_df_path+'nyc_df.pkl', 'rb') as f:\n",
    "    nyc_per_usage = pickle.load(f)\n",
    "    \n",
    "with open(parent_df_path+'ran_df.pkl', 'rb') as f:\n",
    "    ran_per_usage = pickle.load(f)\n",
    "\n",
    "\n",
    "all_usage = pd.concat([joh_per_usage,lon_per_usage,nyc_per_usage,ran_per_usage],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#️⃣</th>\n",
       "      <th>*️⃣</th>\n",
       "      <th>0️⃣</th>\n",
       "      <th>1️⃣</th>\n",
       "      <th>2️⃣</th>\n",
       "      <th>3️⃣</th>\n",
       "      <th>4️⃣</th>\n",
       "      <th>5️⃣</th>\n",
       "      <th>6️⃣</th>\n",
       "      <th>7️⃣</th>\n",
       "      <th>...</th>\n",
       "      <th>🧺</th>\n",
       "      <th>🧻</th>\n",
       "      <th>🧼</th>\n",
       "      <th>🧽</th>\n",
       "      <th>🧾</th>\n",
       "      <th>🧿</th>\n",
       "      <th>tweets_contain_emoji</th>\n",
       "      <th>total_tweets</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>female</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>female</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>887.0</td>\n",
       "      <td>female</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18684</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>3121.0</td>\n",
       "      <td>female</td>\n",
       "      <td>asian/hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18685</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td>3072.0</td>\n",
       "      <td>female</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18686</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>2482.0</td>\n",
       "      <td>male</td>\n",
       "      <td>asian/hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18687</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>905.0</td>\n",
       "      <td>2752.0</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18688</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3206.0</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18689 rows × 2788 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #️⃣  *️⃣  0️⃣  1️⃣  2️⃣  3️⃣  4️⃣  5️⃣  6️⃣  7️⃣  ...    🧺    🧻    🧼  \\\n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "18684  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "18685  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "18686  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "18687  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "18688  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "         🧽    🧾    🧿  tweets_contain_emoji  total_tweets  gender  \\\n",
       "0      0.0  0.0  0.0                  62.0         111.0  female   \n",
       "1      0.0  0.0  0.0                   0.0           2.0  female   \n",
       "2      0.0  0.0  0.0                 566.0         945.0  female   \n",
       "3      0.0  0.0  0.0                 251.0         444.0    male   \n",
       "4      0.0  0.0  0.0                 410.0         887.0  female   \n",
       "...    ...  ...  ...                   ...           ...     ...   \n",
       "18684  0.0  0.0  0.0                 117.0        3121.0  female   \n",
       "18685  0.0  0.0  0.0                 551.0        3072.0  female   \n",
       "18686  0.0  0.0  0.0                1055.0        2482.0    male   \n",
       "18687  0.0  0.0  0.0                 905.0        2752.0  female   \n",
       "18688  0.0  0.0  0.0                  15.0        3206.0    male   \n",
       "\n",
       "            ethnicity  \n",
       "0               black  \n",
       "1               black  \n",
       "2               black  \n",
       "3               white  \n",
       "4               black  \n",
       "...               ...  \n",
       "18684  asian/hispanic  \n",
       "18685           black  \n",
       "18686  asian/hispanic  \n",
       "18687           white  \n",
       "18688           white  \n",
       "\n",
       "[18689 rows x 2788 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_usage.drop(labels = all_usage[all_usage.ethnicity.eq('other')].index,inplace =True)\n",
    "all_usage.reset_index(inplace = True,drop = True)\n",
    "\n",
    "all_usage[\"ethnicity\"].replace({\"asian\":\"asian/hispanic\",\"hispanic\":\"asian/hispanic\"}, inplace=True)\n",
    "all_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gender, X_test_gender, y_train_gender, y_test_gender = train_test_split(all_usage.drop(columns = ['gender','ethnicity']), all_usage['gender'], test_size=0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gender = pd.concat([X_train_gender,X_test_gender],ignore_index = True)\n",
    "y_gender = pd.concat([y_train_gender,y_test_gender],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=100, n_estimators=500)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'max_depth':[70,80,90,100],'criterion':['gini', 'entropy']}\n",
    "\n",
    "rf = GridSearchCV(RandomForestClassifier(n_estimators = 500),parameters)\n",
    "rf.fit(X_gender, y_gender)\n",
    "\n",
    "rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(dual=False, max_iter=10000, tol=0.01)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'penalty': ['l1','l2']}\n",
    "                   \n",
    "svm_Linear = GridSearchCV(LinearSVC(dual = False,tol=1e-2,max_iter = 10000),parameters)\n",
    "svm_Linear.fit(X_gender, y_gender)\n",
    "svm_Linear.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'max_depth':[5,6,7] }\n",
    "\n",
    "GBC = GridSearchCV(GradientBoostingClassifier(loss = 'deviance',criterion='friedman_mse',max_features = None),parameters)\n",
    "GBC.fit(X_gender, y_gender)\n",
    "GBC.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_eth, X_test_eth, y_train_eth, y_test_eth = train_test_split(all_usage.drop(columns = ['gender','ethnicity']), all_usage['ethnicity'], test_size=0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eth = pd.concat([X_train_eth,X_test_eth],ignore_index = True)\n",
    "y_eth = pd.concat([y_train_eth,y_test_eth],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=70, n_estimators=500)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'max_depth':[70,80,90,100],'n_estimators':[100,500],'criterion':['gini', 'entropy']}\n",
    "\n",
    "rf = GridSearchCV(RandomForestClassifier(n_estimators=500,class_weight = 'balanced'),parameters)\n",
    "rf.fit(X_eth, y_eth)\n",
    "rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'penalty': ['l1','l2']}\n",
    "                   \n",
    "svmLinear = GridSearchCV(LinearSVC(dual = False,class_weight = 'balanced',max_iter = 30000),parameters)\n",
    "svmLinear.fit(X_eth, y_eth)\n",
    "svmLinear.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'max_depth':[3,5,7] }\n",
    "                   \n",
    "GBC = GridSearchCV(GradientBoostingClassifier(loss = 'deviance',criterion='friedman_mse',max_features = None),parameters)\n",
    "GBC.fit(X_eth, y_eth)\n",
    "GBC.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
