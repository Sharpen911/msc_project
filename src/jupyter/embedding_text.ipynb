{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, log_loss, f1_score\n",
    "\n",
    "\n",
    "with open('features/text_.pkl', 'rb') as f:\n",
    "    text_feature = pickle.load(f)\n",
    "text_feature.reset_index(inplace = True,drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008789</td>\n",
       "      <td>0.012651</td>\n",
       "      <td>0.021610</td>\n",
       "      <td>0.049692</td>\n",
       "      <td>-0.028779</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.014204</td>\n",
       "      <td>-0.041314</td>\n",
       "      <td>0.018072</td>\n",
       "      <td>0.029904</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045086</td>\n",
       "      <td>-0.006856</td>\n",
       "      <td>-0.013477</td>\n",
       "      <td>-0.024141</td>\n",
       "      <td>-0.006726</td>\n",
       "      <td>-0.029954</td>\n",
       "      <td>-0.006961</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>female</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008530</td>\n",
       "      <td>0.028461</td>\n",
       "      <td>0.005318</td>\n",
       "      <td>0.067734</td>\n",
       "      <td>0.055008</td>\n",
       "      <td>-0.019989</td>\n",
       "      <td>0.035583</td>\n",
       "      <td>0.017593</td>\n",
       "      <td>0.042480</td>\n",
       "      <td>0.036743</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.105774</td>\n",
       "      <td>-0.055145</td>\n",
       "      <td>-0.059845</td>\n",
       "      <td>-0.024338</td>\n",
       "      <td>0.026859</td>\n",
       "      <td>-0.021318</td>\n",
       "      <td>-0.035750</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>female</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.012902</td>\n",
       "      <td>0.018518</td>\n",
       "      <td>0.047201</td>\n",
       "      <td>-0.025636</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.009673</td>\n",
       "      <td>-0.040974</td>\n",
       "      <td>0.012866</td>\n",
       "      <td>0.021796</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041725</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>-0.010792</td>\n",
       "      <td>-0.017471</td>\n",
       "      <td>-0.002344</td>\n",
       "      <td>-0.028302</td>\n",
       "      <td>-0.009627</td>\n",
       "      <td>0.003673</td>\n",
       "      <td>female</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.008376</td>\n",
       "      <td>0.033346</td>\n",
       "      <td>0.025166</td>\n",
       "      <td>0.039505</td>\n",
       "      <td>-0.035254</td>\n",
       "      <td>-0.002669</td>\n",
       "      <td>-0.004571</td>\n",
       "      <td>-0.067053</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033694</td>\n",
       "      <td>0.029808</td>\n",
       "      <td>-0.005777</td>\n",
       "      <td>-0.025186</td>\n",
       "      <td>0.008144</td>\n",
       "      <td>-0.033310</td>\n",
       "      <td>-0.025547</td>\n",
       "      <td>0.017832</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.028307</td>\n",
       "      <td>0.069367</td>\n",
       "      <td>-0.044914</td>\n",
       "      <td>0.004363</td>\n",
       "      <td>0.009267</td>\n",
       "      <td>-0.069754</td>\n",
       "      <td>0.016249</td>\n",
       "      <td>0.026416</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053900</td>\n",
       "      <td>0.012315</td>\n",
       "      <td>-0.019281</td>\n",
       "      <td>-0.033033</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>-0.035452</td>\n",
       "      <td>-0.017373</td>\n",
       "      <td>0.007971</td>\n",
       "      <td>female</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18684</th>\n",
       "      <td>-0.026361</td>\n",
       "      <td>0.024812</td>\n",
       "      <td>0.053901</td>\n",
       "      <td>0.060609</td>\n",
       "      <td>-0.018764</td>\n",
       "      <td>0.011707</td>\n",
       "      <td>-0.004524</td>\n",
       "      <td>-0.051552</td>\n",
       "      <td>-0.016298</td>\n",
       "      <td>0.039940</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032870</td>\n",
       "      <td>0.036651</td>\n",
       "      <td>-0.016086</td>\n",
       "      <td>-0.021088</td>\n",
       "      <td>-0.019377</td>\n",
       "      <td>-0.033959</td>\n",
       "      <td>-0.039759</td>\n",
       "      <td>0.073062</td>\n",
       "      <td>female</td>\n",
       "      <td>asian/hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18685</th>\n",
       "      <td>0.013343</td>\n",
       "      <td>0.017913</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.092750</td>\n",
       "      <td>-0.048378</td>\n",
       "      <td>0.008966</td>\n",
       "      <td>0.019323</td>\n",
       "      <td>-0.071787</td>\n",
       "      <td>0.037604</td>\n",
       "      <td>0.059544</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079811</td>\n",
       "      <td>0.007672</td>\n",
       "      <td>-0.037977</td>\n",
       "      <td>-0.034392</td>\n",
       "      <td>-0.009804</td>\n",
       "      <td>-0.038382</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>female</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18686</th>\n",
       "      <td>-0.014462</td>\n",
       "      <td>0.024962</td>\n",
       "      <td>0.012097</td>\n",
       "      <td>0.016582</td>\n",
       "      <td>-0.025199</td>\n",
       "      <td>-0.003464</td>\n",
       "      <td>-0.006939</td>\n",
       "      <td>-0.047585</td>\n",
       "      <td>-0.004364</td>\n",
       "      <td>-0.004218</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008337</td>\n",
       "      <td>0.027403</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>-0.022498</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>-0.016541</td>\n",
       "      <td>-0.023958</td>\n",
       "      <td>0.019532</td>\n",
       "      <td>male</td>\n",
       "      <td>asian/hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18687</th>\n",
       "      <td>-0.033682</td>\n",
       "      <td>0.041157</td>\n",
       "      <td>0.076247</td>\n",
       "      <td>0.062728</td>\n",
       "      <td>-0.020990</td>\n",
       "      <td>0.038851</td>\n",
       "      <td>-0.012032</td>\n",
       "      <td>-0.072906</td>\n",
       "      <td>-0.004788</td>\n",
       "      <td>0.059211</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020076</td>\n",
       "      <td>0.054280</td>\n",
       "      <td>0.007743</td>\n",
       "      <td>-0.020976</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>-0.057290</td>\n",
       "      <td>-0.045841</td>\n",
       "      <td>0.089262</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18688</th>\n",
       "      <td>-0.019398</td>\n",
       "      <td>0.025799</td>\n",
       "      <td>0.017743</td>\n",
       "      <td>0.039771</td>\n",
       "      <td>-0.006237</td>\n",
       "      <td>0.024023</td>\n",
       "      <td>0.019535</td>\n",
       "      <td>-0.051382</td>\n",
       "      <td>-0.001214</td>\n",
       "      <td>0.033917</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022113</td>\n",
       "      <td>0.048096</td>\n",
       "      <td>-0.037009</td>\n",
       "      <td>-0.045482</td>\n",
       "      <td>-0.046020</td>\n",
       "      <td>-0.017134</td>\n",
       "      <td>-0.036348</td>\n",
       "      <td>0.068621</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18689 rows × 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.008789  0.012651  0.021610  0.049692 -0.028779  0.007299  0.014204   \n",
       "1      0.008530  0.028461  0.005318  0.067734  0.055008 -0.019989  0.035583   \n",
       "2      0.002857  0.012902  0.018518  0.047201 -0.025636  0.002009  0.009673   \n",
       "3     -0.008376  0.033346  0.025166  0.039505 -0.035254 -0.002669 -0.004571   \n",
       "4      0.000440  0.021398  0.028307  0.069367 -0.044914  0.004363  0.009267   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "18684 -0.026361  0.024812  0.053901  0.060609 -0.018764  0.011707 -0.004524   \n",
       "18685  0.013343  0.017913  0.028100  0.092750 -0.048378  0.008966  0.019323   \n",
       "18686 -0.014462  0.024962  0.012097  0.016582 -0.025199 -0.003464 -0.006939   \n",
       "18687 -0.033682  0.041157  0.076247  0.062728 -0.020990  0.038851 -0.012032   \n",
       "18688 -0.019398  0.025799  0.017743  0.039771 -0.006237  0.024023  0.019535   \n",
       "\n",
       "              7         8         9  ...       292       293       294  \\\n",
       "0     -0.041314  0.018072  0.029904  ... -0.045086 -0.006856 -0.013477   \n",
       "1      0.017593  0.042480  0.036743  ... -0.105774 -0.055145 -0.059845   \n",
       "2     -0.040974  0.012866  0.021796  ... -0.041725  0.001207 -0.010792   \n",
       "3     -0.067053  0.001779  0.006642  ... -0.033694  0.029808 -0.005777   \n",
       "4     -0.069754  0.016249  0.026416  ... -0.053900  0.012315 -0.019281   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "18684 -0.051552 -0.016298  0.039940  ... -0.032870  0.036651 -0.016086   \n",
       "18685 -0.071787  0.037604  0.059544  ... -0.079811  0.007672 -0.037977   \n",
       "18686 -0.047585 -0.004364 -0.004218  ... -0.008337  0.027403  0.000495   \n",
       "18687 -0.072906 -0.004788  0.059211  ... -0.020076  0.054280  0.007743   \n",
       "18688 -0.051382 -0.001214  0.033917  ... -0.022113  0.048096 -0.037009   \n",
       "\n",
       "            295       296       297       298       299  gender  \\\n",
       "0     -0.024141 -0.006726 -0.029954 -0.006961  0.000429  female   \n",
       "1     -0.024338  0.026859 -0.021318 -0.035750  0.001282  female   \n",
       "2     -0.017471 -0.002344 -0.028302 -0.009627  0.003673  female   \n",
       "3     -0.025186  0.008144 -0.033310 -0.025547  0.017832    male   \n",
       "4     -0.033033  0.002413 -0.035452 -0.017373  0.007971  female   \n",
       "...         ...       ...       ...       ...       ...     ...   \n",
       "18684 -0.021088 -0.019377 -0.033959 -0.039759  0.073062  female   \n",
       "18685 -0.034392 -0.009804 -0.038382  0.001580 -0.005020  female   \n",
       "18686 -0.022498  0.001039 -0.016541 -0.023958  0.019532    male   \n",
       "18687 -0.020976  0.000783 -0.057290 -0.045841  0.089262  female   \n",
       "18688 -0.045482 -0.046020 -0.017134 -0.036348  0.068621    male   \n",
       "\n",
       "            ethnicity  \n",
       "0               black  \n",
       "1               black  \n",
       "2               black  \n",
       "3               white  \n",
       "4               black  \n",
       "...               ...  \n",
       "18684  asian/hispanic  \n",
       "18685           black  \n",
       "18686  asian/hispanic  \n",
       "18687           white  \n",
       "18688           white  \n",
       "\n",
       "[18689 rows x 302 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_feature.drop(labels = text_feature[text_feature.ethnicity.eq('other')].index,inplace =True)\n",
    "text_feature.reset_index(inplace = True,drop = True)\n",
    "\n",
    "text_feature[\"ethnicity\"].replace({\"asian\":\"asian/hispanic\",\"hispanic\":\"asian/hispanic\"}, inplace=True)\n",
    "text_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gender, X_test_gender, y_train_gender, y_test_gender = train_test_split(text_feature.drop(columns = ['gender','ethnicity']), text_feature['gender'], test_size=0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female      0.814     0.800     0.807      1920\n",
      "        male      0.793     0.807     0.800      1818\n",
      "\n",
      "    accuracy                          0.803      3738\n",
      "   macro avg      0.803     0.803     0.803      3738\n",
      "weighted avg      0.804     0.803     0.803      3738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_linear = LinearSVC(tol=1e-3,dual = False,max_iter=10000,penalty='l1').fit(X_train_gender, y_train_gender) \n",
    "report_SVMlinear = classification_report(svm_linear.predict(X_test_gender),y_test_gender,digits = 3)\n",
    "print(report_SVMlinear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female      0.778     0.783     0.781      1876\n",
      "        male      0.780     0.776     0.778      1862\n",
      "\n",
      "    accuracy                          0.779      3738\n",
      "   macro avg      0.779     0.779     0.779      3738\n",
      "weighted avg      0.779     0.779     0.779      3738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(criterion='entropy', max_depth=70, n_estimators=500).fit(X_train_gender, y_train_gender)\n",
    "report_rf = classification_report(rf.predict(X_test_gender),y_test_gender,digits = 3)\n",
    "print(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female      0.802     0.802     0.802      1887\n",
      "        male      0.798     0.798     0.798      1851\n",
      "\n",
      "    accuracy                          0.800      3738\n",
      "   macro avg      0.800     0.800     0.800      3738\n",
      "weighted avg      0.800     0.800     0.800      3738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GBC = GradientBoostingClassifier(n_estimators=300,max_depth = 7).fit(X_train_gender, y_train_gender)\n",
    "report_GBC = classification_report(GBC.predict(X_test_gender),y_test_gender,digits = 3)\n",
    "print(report_GBC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethnicity prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_eth, X_test_eth, y_train_eth, y_test_eth = train_test_split(text_feature.drop(columns = ['gender','ethnicity']), text_feature['ethnicity'], test_size=0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "asian/hispanic      0.607     0.511     0.555       356\n",
      "         black      0.858     0.877     0.868      1509\n",
      "         white      0.854     0.864     0.859      1873\n",
      "\n",
      "      accuracy                          0.836      3738\n",
      "     macro avg      0.773     0.751     0.761      3738\n",
      "  weighted avg      0.832     0.836     0.834      3738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_linear = LinearSVC(class_weight='balanced', dual=False, max_iter=15000, penalty='l1',tol=1e-2).fit(X_train_eth, y_train_eth) \n",
    "report_SVMlinear = classification_report(svm_linear.predict(X_test_eth),y_test_eth,digits = 3,zero_division = 0)\n",
    "print(report_SVMlinear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "asian/hispanic      0.457     0.806     0.583       170\n",
      "         black      0.801     0.871     0.835      1419\n",
      "         white      0.909     0.802     0.852      2149\n",
      "\n",
      "      accuracy                          0.828      3738\n",
      "     macro avg      0.722     0.826     0.757      3738\n",
      "  weighted avg      0.848     0.828     0.833      3738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(class_weight='balanced', criterion='entropy',max_depth=90, n_estimators=500).fit(X_train_eth, y_train_eth)\n",
    "report_rf = classification_report(rf.predict(X_test_eth),y_test_eth,digits = 3,zero_division = 0)\n",
    "print(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "asian/hispanic      0.473     0.816     0.599       174\n",
      "         black      0.843     0.889     0.865      1462\n",
      "         white      0.915     0.825     0.868      2102\n",
      "\n",
      "      accuracy                          0.850      3738\n",
      "     macro avg      0.744     0.843     0.777      3738\n",
      "  weighted avg      0.866     0.850     0.854      3738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GBC = GradientBoostingClassifier(n_estimators=300,max_depth = 7).fit(X_train_eth, y_train_eth)\n",
    "report_GBC = classification_report(GBC.predict(X_test_eth),y_test_eth,digits = 3)\n",
    "print(report_GBC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
